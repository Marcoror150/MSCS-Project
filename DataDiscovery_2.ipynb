{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NHTSA Data Discovery Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mode\n",
    "\n",
    "from io import StringIO\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestClassifier # This is testing, will review classifiers and modeling options soon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accidents = pd.read_csv(\"Data/2015/accident.csv\")\n",
    "df_vehicles = pd.read_csv(\"Data/2015/vehicle.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATE 51\n",
      "ST_CASE 32538\n",
      "PVH_INVL 10\n",
      "PERNOTMVIT 12\n",
      "PERMVIT 37\n",
      "PERSONS 36\n",
      "MAN_COLL 11\n",
      "FATALS 8\n",
      "DRUNK_DR 4\n"
     ]
    }
   ],
   "source": [
    "toRemove = (\"COUNTY\", \"CITY\", \"TWAY_ID\", \"TWAY_ID2\", \"VE_TOTAL\", \n",
    "            \"VE_FORMS\", \"YEAR\", \"NHS\", \"MILEPT\", \"LATITUDE\", \"LONGITUD\", \n",
    "            \"RELJCT1\", \"RELJCT2\", \"TYP_INT\", \"REL_ROAD\", \"PEDS\", \n",
    "            \"DAY\", \"MONTH\", \"DAY_WEEK\", \"HOUR\", \"MINUTE\", \"RUR_URB\",\n",
    "            \"HOSP_HR\", \"HOSP_MN\", \"NOT_HOUR\", \"NOT_MIN\", \"ARR_HOUR\",\n",
    "            \"ARR_MIN\", \"SP_JUR\", \"LGT_COND\", \"ROUTE\", \"RAIL\", \"WEATHER\",\n",
    "            \"WEATHER1\", \"WEATHER2\", \"WRK_ZONE\", \"HARM_EV\", \"FUNC_SYS\",\n",
    "            \"RD_OWNER\", \"CF1\", \"CF2\", \"CF3\", \"SCH_BUS\")\n",
    "df_accidents_copy = df_accidents\n",
    "\n",
    "for item in toRemove:\n",
    "    if item in df_accidents_copy:\n",
    "        del df_accidents_copy[item]\n",
    "\n",
    "#How many unique values?\n",
    "for column in df_accidents_copy:\n",
    "    print(column, len(df_accidents_copy[column].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ST_CASE 32166\n",
      "MAKE 68\n",
      "MODEL 130\n",
      "MOD_YEAR 77\n"
     ]
    }
   ],
   "source": [
    "vehiclesToKeep = [\"ST_CASE\", \"MAKE\", \"MODEL\", \"MOD_YEAR\"]\n",
    "df_vehicles_copy = df_vehicles[vehiclesToKeep]\n",
    "\n",
    "\n",
    "#How many unique values?\n",
    "for column in df_vehicles_copy:\n",
    "    print(column, len(df_vehicles_copy[column].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find blank or whitespace\n",
    "df_vehicles = df_vehicles.replace(r'\\s+\\t+', np.nan, regex=True).replace('', np.nan)\n",
    "\n",
    "#Find blank or whitespace\n",
    "df_accidents = df_accidents.replace(r'\\s+\\t+', np.nan, regex=True).replace('', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = pd.merge(df_accidents_copy, df_vehicles_copy, on=\"ST_CASE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48864"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge['MULTI_FATAL'] = np.where(df_merge['FATALS']>1, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STATE          object\n",
       "ST_CASE        object\n",
       "PVH_INVL        int64\n",
       "PERNOTMVIT      int64\n",
       "PERMVIT         int64\n",
       "PERSONS         int64\n",
       "MAN_COLL        int64\n",
       "FATALS          int64\n",
       "DRUNK_DR        int64\n",
       "MAKE           object\n",
       "MODEL          object\n",
       "MOD_YEAR       object\n",
       "MULTI_FATAL      bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.astype({'STATE':'str', 'ST_CASE':'str', 'MAKE':'str', 'MODEL':'str', 'MOD_YEAR':'str'}).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9028649386084584\n",
      "[[6613   44]\n",
      " [ 668    5]]\n"
     ]
    }
   ],
   "source": [
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=df_merge[['MAKE', 'MODEL', 'MOD_YEAR']]  # Features\n",
    "y=df_merge['MULTI_FATAL']  # Labels\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, shuffle=True) # 85% training and 15% test\n",
    "\n",
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=1000)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9038199181446112\n"
     ]
    }
   ],
   "source": [
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=df_merge[['MAKE', 'MODEL', 'MOD_YEAR']]  # Features\n",
    "y=df_merge['MULTI_FATAL']  # Labels\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test\n",
    "\n",
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=1000)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.905525238744884\n"
     ]
    }
   ],
   "source": [
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=df_merge[['MAKE', 'MODEL', 'MOD_YEAR']]  # Features\n",
    "y=df_merge['FATALS']  # Labels\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle = True) # 70% training and 30% test\n",
    "\n",
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=1000)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Attempt to fix this issue where so much of our data is in fact a 1 fatality crash\n",
    "print(df_merge.groupby(['MAKE', 'MODEL','MULTI_FATAL']).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     44519\n",
      "2      3533\n",
      "3       564\n",
      "4       150\n",
      "5        72\n",
      "6        24\n",
      "10        1\n",
      "8         1\n",
      "Name: FATALS, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Attempt to fix this issue where so much of our data is in fact a 1 fatality crash\n",
    "print(df_merge['FATALS'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/20250771/remap-values-in-pandas-column-with-a-dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44519\n",
      "4345\n",
      "4345\n"
     ]
    }
   ],
   "source": [
    "df_merge_1fatal = df_merge.loc[df_merge['MULTI_FATAL'] == False]\n",
    "print(len(df_merge_1fatal))\n",
    "df_merge_Nfatal = df_merge.loc[df_merge['MULTI_FATAL'] == True]\n",
    "print(len(df_merge_Nfatal))\n",
    "\n",
    "df_merge_1fatal_sample = df_merge_1fatal.sample(n=len(df_merge_Nfatal), replace=False)\n",
    "print(len(df_merge_1fatal_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       STATE  ST_CASE  PVH_INVL  PERNOTMVIT  PERMVIT  PERSONS  MAN_COLL  \\\n",
      "10447     12   120972         0           0        5        5        11   \n",
      "6425       6    62106         0           1        6        6         0   \n",
      "22068     25   250017         0           1        1        1         0   \n",
      "5080       6    61258         0           0        6        6         6   \n",
      "35631     41   410374         0           0        4        4         2   \n",
      "\n",
      "       FATALS  DRUNK_DR  MAKE  MODEL  MOD_YEAR  MULTI_FATAL  \n",
      "10447       2         0    34     34      2013         True  \n",
      "6425        1         0    42     42      2012        False  \n",
      "22068       1         0    82    884      2007        False  \n",
      "5080        1         0    73    703      2013        False  \n",
      "35631       1         0    49     40      2007        False  \n",
      "8690\n"
     ]
    }
   ],
   "source": [
    "df_merge_1fatal_sample_rebrand = df_merge_1fatal_sample.copy()\n",
    "df_merge_1fatal_sample_rebrand['MULTI_FATAL'] = False\n",
    "\n",
    "df_merge_Nfatal_rebrand = df_merge_Nfatal.copy()\n",
    "df_merge_Nfatal_rebrand['MULTI_FATAL'] = True\n",
    "\n",
    "frames = [df_merge_Nfatal_rebrand, df_merge_1fatal_sample_rebrand]\n",
    "\n",
    "df_merge_concat = pd.concat(frames).sample(frac=1)\n",
    "print(df_merge_concat.head())\n",
    "print(len(df_merge_concat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6060606060606061\n"
     ]
    }
   ],
   "source": [
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=df_merge_concat[['MAKE', 'MODEL', 'MOD_YEAR']]  # Features\n",
    "y=df_merge_concat['FATALS']  # Labels\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4) # 70% training and 30% test\n",
    "\n",
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=500)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[552 104   0   0   0   0   0]\n",
      " [449  69   0   0   0   0   0]\n",
      " [ 82  11   0   0   0   0   0]\n",
      " [ 19   2   0   0   0   0   0]\n",
      " [ 10   0   0   0   0   0   0]\n",
      " [  5   0   0   0   0   0   0]\n",
      " [  1   0   0   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.84      0.62       656\n",
      "           2       0.37      0.13      0.20       518\n",
      "           3       0.00      0.00      0.00        93\n",
      "           4       0.00      0.00      0.00        21\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         5\n",
      "          10       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.48      1304\n",
      "   macro avg       0.12      0.14      0.12      1304\n",
      "weighted avg       0.40      0.48      0.39      1304\n",
      "\n",
      "Accuracy: 0.4762269938650307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mulic\\.virtualenvs\\mscs-project-hxj6hwao\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# - https://stackabuse.com/implementing-svm-and-kernel-svm-with-pythons-scikit-learn/\n",
    "# Try and use an SVM# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=df_merge_concat[['MAKE', 'MODEL', 'MOD_YEAR']]  # Features\n",
    "y=df_merge_concat['FATALS']  # Labels\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15) # 85% training and 15% test\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='linear')\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "svclassifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svclassifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13342     4     0     0     0     0     0]\n",
      " [ 1055     0     0     0     0     0     0]\n",
      " [  189     0     0     0     0     0     0]\n",
      " [   45     0     0     0     0     0     0]\n",
      " [   17     0     0     0     0     0     0]\n",
      " [    7     0     0     0     0     0     0]\n",
      " [    1     0     0     0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      1.00      0.95     13346\n",
      "           2       0.00      0.00      0.00      1055\n",
      "           3       0.00      0.00      0.00       189\n",
      "           4       0.00      0.00      0.00        45\n",
      "           5       0.00      0.00      0.00        17\n",
      "           6       0.00      0.00      0.00         7\n",
      "          10       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.91     14660\n",
      "   macro avg       0.13      0.14      0.14     14660\n",
      "weighted avg       0.83      0.91      0.87     14660\n",
      "\n",
      "Accuracy: 0.9100954979536153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mulic\\.virtualenvs\\mscs-project-hxj6hwao\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# - https://stackabuse.com/implementing-svm-and-kernel-svm-with-pythons-scikit-learn/\n",
    "# Try and use an SVM# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=df_merge[['MAKE', 'MODEL', 'MOD_YEAR']]  # Features\n",
    "y=df_merge['FATALS']  # Labels\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 20% test\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='linear')\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "svclassifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svclassifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
