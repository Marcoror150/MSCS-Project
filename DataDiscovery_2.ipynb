{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NHTSA Data Discovery Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mode\n",
    "\n",
    "from io import StringIO\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestClassifier # This is testing, will review classifiers and modeling options soon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accidents = pd.read_csv(\"Data/2015/accident.csv\")\n",
    "df_vehicles = pd.read_csv(\"Data/2015/vehicle.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATE 51\n",
      "ST_CASE 32538\n",
      "PVH_INVL 10\n",
      "PERNOTMVIT 12\n",
      "PERMVIT 37\n",
      "PERSONS 36\n",
      "MAN_COLL 11\n",
      "FATALS 8\n",
      "DRUNK_DR 4\n"
     ]
    }
   ],
   "source": [
    "toRemove = (\"COUNTY\", \"CITY\", \"TWAY_ID\", \"TWAY_ID2\", \"VE_TOTAL\", \n",
    "            \"VE_FORMS\", \"YEAR\", \"NHS\", \"MILEPT\", \"LATITUDE\", \"LONGITUD\", \n",
    "            \"RELJCT1\", \"RELJCT2\", \"TYP_INT\", \"REL_ROAD\", \"PEDS\", \n",
    "            \"DAY\", \"MONTH\", \"DAY_WEEK\", \"HOUR\", \"MINUTE\", \"RUR_URB\",\n",
    "            \"HOSP_HR\", \"HOSP_MN\", \"NOT_HOUR\", \"NOT_MIN\", \"ARR_HOUR\",\n",
    "            \"ARR_MIN\", \"SP_JUR\", \"LGT_COND\", \"ROUTE\", \"RAIL\", \"WEATHER\",\n",
    "            \"WEATHER1\", \"WEATHER2\", \"WRK_ZONE\", \"HARM_EV\", \"FUNC_SYS\",\n",
    "            \"RD_OWNER\", \"CF1\", \"CF2\", \"CF3\", \"SCH_BUS\")\n",
    "df_accidents_copy = df_accidents\n",
    "\n",
    "for item in toRemove:\n",
    "    if item in df_accidents_copy:\n",
    "        del df_accidents_copy[item]\n",
    "\n",
    "#How many unique values?\n",
    "for column in df_accidents_copy:\n",
    "    print(column, len(df_accidents_copy[column].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ST_CASE 32166\n",
      "MAKE 68\n",
      "MODEL 130\n",
      "MOD_YEAR 77\n"
     ]
    }
   ],
   "source": [
    "vehiclesToKeep = [\"ST_CASE\", \"MAKE\", \"MODEL\", \"MOD_YEAR\"]\n",
    "df_vehicles_copy = df_vehicles[vehiclesToKeep]\n",
    "\n",
    "\n",
    "#How many unique values?\n",
    "for column in df_vehicles_copy:\n",
    "    print(column, len(df_vehicles_copy[column].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find blank or whitespace\n",
    "df_vehicles = df_vehicles.replace(r'\\s+\\t+', np.nan, regex=True).replace('', np.nan)\n",
    "\n",
    "#Find blank or whitespace\n",
    "df_accidents = df_accidents.replace(r'\\s+\\t+', np.nan, regex=True).replace('', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = pd.merge(df_accidents_copy, df_vehicles_copy, on=\"ST_CASE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48864"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge['MULTI_FATAL'] = np.where(df_merge['FATALS']>1, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STATE          object\n",
       "ST_CASE        object\n",
       "PVH_INVL        int64\n",
       "PERNOTMVIT      int64\n",
       "PERMVIT         int64\n",
       "PERSONS         int64\n",
       "MAN_COLL        int64\n",
       "FATALS          int64\n",
       "DRUNK_DR        int64\n",
       "MAKE           object\n",
       "MODEL          object\n",
       "MOD_YEAR       object\n",
       "MULTI_FATAL      bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.astype({'STATE':'str', 'ST_CASE':'str', 'MAKE':'str', 'MODEL':'str', 'MOD_YEAR':'str'}).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9028649386084584\n",
      "[[6613   44]\n",
      " [ 668    5]]\n"
     ]
    }
   ],
   "source": [
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=df_merge[['MAKE', 'MODEL', 'MOD_YEAR']]  # Features\n",
    "y=df_merge['MULTI_FATAL']  # Labels\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, shuffle=True) # 85% training and 15% test\n",
    "\n",
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=1000)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9038199181446112\n"
     ]
    }
   ],
   "source": [
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=df_merge[['MAKE', 'MODEL', 'MOD_YEAR']]  # Features\n",
    "y=df_merge['MULTI_FATAL']  # Labels\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test\n",
    "\n",
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=1000)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.905525238744884\n"
     ]
    }
   ],
   "source": [
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=df_merge[['MAKE', 'MODEL', 'MOD_YEAR']]  # Features\n",
    "y=df_merge['FATALS']  # Labels\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle = True) # 70% training and 30% test\n",
    "\n",
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=1000)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Attempt to fix this issue where so much of our data is in fact a 1 fatality crash\n",
    "print(df_merge.groupby(['MAKE', 'MODEL','MULTI_FATAL']).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     44519\n",
      "2      3533\n",
      "3       564\n",
      "4       150\n",
      "5        72\n",
      "6        24\n",
      "10        1\n",
      "8         1\n",
      "Name: FATALS, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Attempt to fix this issue where so much of our data is in fact a 1 fatality crash\n",
    "print(df_merge['FATALS'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/20250771/remap-values-in-pandas-column-with-a-dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44519\n",
      "4345\n",
      "21725\n"
     ]
    }
   ],
   "source": [
    "df_merge_1fatal = df_merge.loc[df_merge['MULTI_FATAL'] == False]\n",
    "print(len(df_merge_1fatal))\n",
    "df_merge_Nfatal = df_merge.loc[df_merge['MULTI_FATAL'] == True]\n",
    "print(len(df_merge_Nfatal))\n",
    "\n",
    "df_merge_1fatal_sample = df_merge_1fatal.sample(n=5*len(df_merge_Nfatal), replace=False)\n",
    "print(len(df_merge_1fatal_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       STATE  ST_CASE  PVH_INVL  PERNOTMVIT  PERMVIT  PERSONS  MAN_COLL  \\\n",
      "12445     12   122313         0           0        2        2         2   \n",
      "13038     12   122709         0           0        2        2         0   \n",
      "28603     35   350038         0           0        2        2         0   \n",
      "7853       8    80136         0           0        5        5         6   \n",
      "16386     17   170533         1           1        6        6         8   \n",
      "\n",
      "       FATALS  DRUNK_DR  MAKE  MODEL  MOD_YEAR  MULTI_FATAL  \n",
      "12445       2         0    35     51      2015         True  \n",
      "13038       1         1    12      3      2004        False  \n",
      "28603       2         0    37     32      2004         True  \n",
      "7853        3         0    12    471      1998         True  \n",
      "16386       2         0    20     25      2015         True  \n",
      "8690\n"
     ]
    }
   ],
   "source": [
    "df_merge_1fatal_sample_rebrand = df_merge_1fatal_sample.copy()\n",
    "df_merge_1fatal_sample_rebrand['MULTI_FATAL'] = False\n",
    "\n",
    "df_merge_Nfatal_rebrand = df_merge_Nfatal.copy()\n",
    "df_merge_Nfatal_rebrand['MULTI_FATAL'] = True\n",
    "\n",
    "frames = [df_merge_Nfatal_rebrand, df_merge_1fatal_sample_rebrand]\n",
    "\n",
    "df_merge_concat = pd.concat(frames).sample(frac=1)\n",
    "print(df_merge_concat.head())\n",
    "print(len(df_merge_concat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6060606060606061\n"
     ]
    }
   ],
   "source": [
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=df_merge_concat[['MAKE', 'MODEL', 'MOD_YEAR']]  # Features\n",
    "y=df_merge_concat['FATALS']  # Labels\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4) # 70% training and 30% test\n",
    "\n",
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=500)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 392  888]\n",
      " [ 295 1032]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.57      0.31      0.40      1280\n",
      "        True       0.54      0.78      0.64      1327\n",
      "\n",
      "    accuracy                           0.55      2607\n",
      "   macro avg       0.55      0.54      0.52      2607\n",
      "weighted avg       0.55      0.55      0.52      2607\n",
      "\n",
      "Accuracy: 0.5462217107786728\n"
     ]
    }
   ],
   "source": [
    "# - https://stackabuse.com/implementing-svm-and-kernel-svm-with-pythons-scikit-learn/\n",
    "# Try and use an SVM# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=df_merge_concat[['MAKE', 'MODEL', 'MOD_YEAR']]  # Features\n",
    "y=df_merge_concat['MULTI_FATAL']  # Labels\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='linear')\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "svclassifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svclassifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svclassifier.predict([[\"12\", \"81\", \"2007\"], [\"12\", \"81\", \"2007\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
